# app.py

import streamlit as st
import pandas as pd
import joblib
import os
import kagglehub
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from tensorflow import keras
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.model_selection import train_test_split
import numpy as np

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="An√°lise e Predi√ß√£o de Manuten√ß√£o de Pavimentos",
    page_icon="üõ£Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- FUN√á√ïES DE CACHE E CARREGAMENTO ---
@st.cache_resource
def load_data_and_model():
    """Carrega dados e modelos com cache para melhor performance."""
    try:
        # Cria o diret√≥rio 'models' se n√£o existir
        os.makedirs("models", exist_ok=True)
        
        # Carrega o dataset do Kaggle
        path = kagglehub.dataset_download("gifreysulay/pavement-dataset")
        
        # O dataset vem num arquivo zip, ent√£o precisamos encontrar o CSV dentro dele
        csv_file_path = ""
        for f in os.listdir(path):
            if f.endswith('.csv'):
                csv_file_path = os.path.join(path, f)
                break
        
        if not csv_file_path:
            st.error("Arquivo CSV n√£o encontrado no dataset do Kaggle.")
            return None, None, None, None, None, None

        df_pavement = pd.read_csv(csv_file_path)
        df_pavement = df_pavement.sample(10000, random_state=42)

        # Caminhos dos modelos e do hist√≥rico
        MODEL_PATH = os.path.join("models", "best_pavement_model.keras")
        PIPELINE_PATH = os.path.join("models", "pavement_preprocessor.pkl")
        HISTORY_PATH = os.path.join("models", "training_history.pkl")

        # Carrega o modelo, pipeline e hist√≥rico
        model = keras.models.load_model(MODEL_PATH)
        pipeline = joblib.load(PIPELINE_PATH)
        history = joblib.load(HISTORY_PATH)
        
        st.success("‚úÖ Dados e modelos carregados com sucesso!")
        return df_pavement, model, pipeline, history

    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dados/modelo: {e}")
        st.info("Certifique-se de que os arquivos 'best_pavement_model.keras', 'pavement_preprocessor.pkl', e 'training_history.pkl' est√£o na pasta 'models'.")
        return None, None, None, None

# --- CARREGAMENTO INICIAL ---
df, model, pipeline, history = load_data_and_model()

# --- SIDEBAR DE NAVEGA√á√ÉO ---
st.sidebar.title("üõ£Ô∏è An√°lise e Predi√ß√£o de Manuten√ß√£o de Pavimentos")
st.sidebar.markdown("---")
page = st.sidebar.radio(
    "Navegue pelas se√ß√µes:",
    ["Predi√ß√£o em Tempo Real", "An√°lise Explorat√≥ria", "Modelagem & M√©tricas", "Vis√£o Geral dos Dados"]
)
st.sidebar.markdown("---")
st.sidebar.info(
    """
    **Desenvolvido por:** Wallas Borges Ara√∫jo  
    """
)
# --- SE√á√ÉO DE PREDI√á√ÉO ---
def prediction_section():
    st.header("üîÆ Predi√ß√£o de Necessidade de Manuten√ß√£o")
    st.markdown("Insira os dados do segmento de pavimento para obter uma predi√ß√£o em tempo real.")

    # Formul√°rio para entrada do usu√°rio
    with st.form("prediction_form"):
        col1, col2, col3 = st.columns(3)

        with col1:
            pci = st.slider("√çndice de Condi√ß√£o do Pavimento (PCI)", 0.0, 100.0, 50.0, 0.1)
            rutting = st.slider("Afundamento (Rutting em mm)", 8.0, 23.0, 15.0, 0.1)
            road_type = st.selectbox("Tipo de Via (Road Type)", options=df['Road Type'].unique(), index=0)

        with col2:
            aadt = st.number_input("Tr√°fego M√©dio Di√°rio Anual (AADT)", min_value=0, max_value=200000, value=10000)
            iri = st.slider("√çndice de Irregularidade Internacional (IRI)", 0.0, 2.0, 0.8, 0.01)
            asphalt_type = st.selectbox("Tipo de Asfalto (Asphalt Type)", options=df['Asphalt Type'].unique(), index=0)

        with col3:
            last_maintenance = st.number_input("Ano da √öltima Manuten√ß√£o", min_value=1950, max_value=2025, value=2018)
            avg_rainfall = st.slider("Precipita√ß√£o M√©dia Anual (mm)", 10.0, 120.0, 65.0, 0.1)
        
        submit_button = st.form_submit_button("Executar Predi√ß√£o")

    if submit_button:
        # Criar DataFrame com os dados de entrada
        input_data = pd.DataFrame({
            'PCI': [pci],
            'Road Type': [road_type],
            'AADT': [aadt],
            'Asphalt Type': [asphalt_type],
            'Last Maintenance': [last_maintenance],
            'Average Rainfall': [avg_rainfall],
            'Rutting': [rutting],
            'IRI': [iri]
        })

        st.markdown("---")
        st.subheader("Dados Inseridos pelo Usu√°rio:")
        st.dataframe(input_data)

        # Pr√©-processar os dados e fazer a predi√ß√£o original
        processed_data = pipeline.transform(input_data)
        prediction_proba = model.predict(processed_data)[0][0]
        prediction = 1 if prediction_proba > 0.5 else 0

        # Exibir o resultado
        st.subheader("Resultado da Predi√ß√£o:")
        if prediction == 1:
            st.error(f"üö® **Precisa de Manuten√ß√£o** (Probabilidade: {prediction_proba:.2%})")
        else:
            st.success(f"‚úÖ **N√£o Precisa de Manuten√ß√£o** (Probabilidade de precisar: {prediction_proba:.2%})")

        st.progress(float(prediction_proba))
        st.markdown("---")

        # --- AN√ÅLISE T√âCNICA DE SENSIBILIDADE COM GR√ÅFICO ---
        with st.expander("üî¨ Clique para ver a An√°lise T√©cnica Detalhada"):
            st.subheader("An√°lise de Contribui√ß√£o dos Atributos")
            st.markdown("""
            O gr√°fico interativo abaixo mostra o impacto de cada atributo na predi√ß√£o. Simulamos o "pior cen√°rio" para cada vari√°vel e medimos o quanto a probabilidade de manuten√ß√£o **aumentaria**. 
            
            **Passe o mouse sobre as barras para ver os detalhes.**
            """)

            feature_impacts = {}
            # Definimos os piores cen√°rios para cada atributo
            worst_scenarios = {
                'PCI': df['PCI'].min(),
                'Rutting': df['Rutting'].max(),
                'IRI': df['IRI'].max(),
                'Last Maintenance': df['Last Maintenance'].min(),
                'AADT': df['AADT'].max(),
                'Average Rainfall': df['Average Rainfall'].max()
            }

            for feature, worst_value in worst_scenarios.items():
                temp_data = input_data.copy()
                temp_data[feature] = worst_value
                temp_processed = pipeline.transform(temp_data)
                new_proba = model.predict(temp_processed)[0][0]
                impact = new_proba - prediction_proba
                # Garantimos que o impacto n√£o seja negativo (s√≥ nos interessa o aumento do risco)
                feature_impacts[feature] = max(0, impact)

            # Ordena os atributos pelo maior impacto e cria um DataFrame
            sorted_impacts = sorted(feature_impacts.items(), key=lambda item: item[1], reverse=False) # Invertido para plotagem correta
            impact_df = pd.DataFrame(sorted_impacts, columns=['Atributo', 'Impacto na Probabilidade'])

            # Cria o gr√°fico de barras interativo com Plotly
            fig = px.bar(
                impact_df,
                x='Impacto na Probabilidade',
                y='Atributo',
                orientation='h',
                title='Sensibilidade da Predi√ß√£o a Piores Cen√°rios',
                text='Impacto na Probabilidade'
            )
            
            # Melhora a formata√ß√£o do gr√°fico
            fig.update_traces(
                texttemplate='%{text:.2%}', 
                textposition='outside',
                marker_color='#EF553B' # Cor vermelha para indicar risco
            )
            fig.update_layout(
                yaxis_title="Atributo",
                xaxis_title="Aumento na Probabilidade de Manuten√ß√£o",
                xaxis_tickformat='.0%',
                uniformtext_minsize=8, 
                uniformtext_mode='hide'
            )
            
            st.plotly_chart(fig, use_container_width=True)

            st.subheader("An√°lise dos Fatores Chave")
            st.markdown("""
            Com base no comportamento geral do modelo, observe os seguintes fatores de risco:

            * **Fatores que AUMENTAM a necessidade de manuten√ß√£o:**
                * üìâ **PCI baixo:** Valores abaixo de 60-70 s√£o um forte indicativo.
                * üìà **Rutting (Afundamento) alto:** Geralmente acima de 15-18mm.
                * üìà **IRI (Irregularidade) alto:** Valores se aproximando de 1.5 ou mais.
                * üóìÔ∏è **√öltima Manuten√ß√£o distante:** Anos muito antigos aumentam significativamente o risco.

            * **Fatores que DIMINUEM a necessidade de manuten√ß√£o:**
                * üìà **PCI alto:** Pavimentos com PCI acima de 85 raramente necessitam de interven√ß√£o imediata.
                * üìâ **Rutting e IRI baixos:** Indicam uma superf√≠cie de boa qualidade.
                * üÜï **Manuten√ß√£o Recente:** Interven√ß√µes nos √∫ltimos anos reduzem drasticamente a necessidade de uma nova.
            """)

# --- SE√á√ÉO DE AN√ÅLISE EXPLORAT√ìRIA (EDA) ---
def eda_section():
    st.header("üìä An√°lise Explorat√≥ria dos Dados (EDA)")
    st.markdown("Visualiza√ß√µes interativas para entender a distribui√ß√£o e correla√ß√£o dos dados.")

    st.subheader("Distribui√ß√£o da Vari√°vel Alvo")
    target_dist = df['Needs Maintenance'].value_counts().reset_index()
    target_dist.columns = ['Status', 'Contagem']
    target_dist['Status'] = target_dist['Status'].map({0: 'N√£o Precisa', 1: 'Precisa'})
    fig = px.pie(target_dist, names='Status', values='Contagem', title='Distribui√ß√£o de "Needs Maintenance"', color='Status', color_discrete_map={'N√£o Precisa':'green', 'Precisa':'red'})
    st.plotly_chart(fig, use_container_width=True)
    st.markdown("""
    - A vari√°vel alvo est√° perfeitamente balanceada, o que √© ideal para o treinamento de um modelo de classifica√ß√£o.
    """)
    st.markdown("---")
    
    st.subheader("Distribui√ß√£o das Vari√°veis Num√©ricas")
    numeric_features = ['PCI', 'IRI', 'Rutting', 'AADT', 'Last Maintenance', 'Average Rainfall']
    feature_to_plot = st.selectbox("Selecione uma vari√°vel para visualizar a distribui√ß√£o:", numeric_features)
    fig = px.histogram(df, x=feature_to_plot, color='Needs Maintenance', marginal="box", hover_data=df.columns,
                       title=f'Distribui√ß√£o de {feature_to_plot} por Classe de Manuten√ß√£o',
                       color_discrete_map={0:'green', 1:'red'})
    st.plotly_chart(fig, use_container_width=True)
    st.markdown("""
    - **PCI (√çndice de Condi√ß√£o do Pavimento):** Valores mais baixos est√£o fortemente associados √† necessidade de manuten√ß√£o.
    - **Rutting (Afundamento):** Valores mais altos indicam maior probabilidade de manuten√ß√£o.
    - A an√°lise das outras vari√°veis tamb√©m mostra separa√ß√µes claras entre as classes, indicando seu poder preditivo.
    """)
    st.markdown("---")

    st.subheader("Matriz de Correla√ß√£o")
    corr_matrix = df[numeric_features].corr()
    fig_corr = px.imshow(corr_matrix, text_auto=True, aspect="auto", color_continuous_scale='RdBu_r',
                     title='Correla√ß√£o entre Vari√°veis Num√©ricas')
    st.plotly_chart(fig_corr, use_container_width=True)
    st.markdown("""
    - As correla√ß√µes mais fortes s√£o observadas entre **Rutting e PCI** (negativa) e **Average Rainfall e Rutting** (positiva), o que faz sentido intuitivo.
    """)

# --- SE√á√ÉO DE MODELAGEM E M√âTRICAS ---
def modeling_section():
    st.header("‚öôÔ∏è Modelagem e M√©tricas de Avalia√ß√£o")
    st.markdown("Avalia√ß√£o da performance do modelo de Redes Neurais.")

    # Preparar dados para reavalia√ß√£o
    X = df.drop(['Needs Maintenance', 'Segment ID'], axis=1)
    y = df['Needs Maintenance']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    X_test_processed = pipeline.transform(X_test)
    y_pred_proba = model.predict(X_test_processed)
    y_pred = (y_pred_proba > 0.5).astype(int)

    st.subheader("Curvas de Treinamento")
    fig, ax = plt.subplots(1, 2, figsize=(14, 5))
    # Curva de Acur√°cia
    ax[0].plot(history['accuracy'], label='Acur√°cia de Treino')
    ax[0].plot(history['val_accuracy'], label='Acur√°cia de Valida√ß√£o')
    ax[0].set_title('Acur√°cia por √âpoca')
    ax[0].set_xlabel('√âpoca')
    ax[0].set_ylabel('Acur√°cia')
    ax[0].legend()
    # Curva de Perda
    ax[1].plot(history['loss'], label='Perda de Treino')
    ax[1].plot(history['val_loss'], label='Perda de Valida√ß√£o')
    ax[1].set_title('Perda por √âpoca')
    ax[1].set_xlabel('√âpoca')
    ax[1].set_ylabel('Perda')
    ax[1].legend()
    st.pyplot(fig)

    st.subheader("M√©tricas de Classifica√ß√£o")
    report = classification_report(y_test, y_pred, output_dict=True)
    st.dataframe(pd.DataFrame(report).transpose())

    st.subheader("M√©tricas Principais")
    acc = report['accuracy']
    recall = report['1']['recall']
    f1 = report['1']['f1-score']
    
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    roc_auc = auc(fpr, tpr)

    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Acur√°cia", f"{acc:.2%}")
    m2.metric("Recall (Classe 1)", f"{recall:.2%}")
    m3.metric("F1-Score (Classe 1)", f"{f1:.2%}")
    m4.metric("ROC AUC", f"{roc_auc:.3f}")
    
    st.markdown("---")
    
    col3, col4 = st.columns(2)
    with col3:
        st.subheader("Matriz de Confus√£o")
        cm = confusion_matrix(y_test, y_pred)
        fig_cm = px.imshow(cm, text_auto=True, aspect="auto",
                           labels=dict(x="Predito", y="Verdadeiro"),
                           x=['N√£o Precisa', 'Precisa'],
                           y=['N√£o Precisa', 'Precisa'],
                           color_continuous_scale='Greens')
        st.plotly_chart(fig_cm, use_container_width=True)

    with col4:
        st.subheader("Curva ROC")
        fig_roc = go.Figure()
        fig_roc.add_shape(type='line', line=dict(dash='dash'),x0=0, x1=1, y0=0, y1=1)
        fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, name=f'AUC={roc_auc:.3f}', mode='lines'))
        fig_roc.update_layout(
                              xaxis_title='Taxa de Falsos Positivos',
                              yaxis_title='Taxa de Verdadeiros Positivos',
                              yaxis=dict(scaleanchor="x", scaleratio=1),
                              xaxis=dict(constrain='domain'))
        st.plotly_chart(fig_roc, use_container_width=True)

# --- SE√á√ÉO DE VIS√ÉO GERAL DOS DADOS ---
def data_overview_section():
    st.header("üìÑ Vis√£o Geral do Dataset")
    st.markdown("Uma amostra dos dados utilizados para treinar o modelo.")
    
    st.subheader("Amostra do DataFrame")
    st.dataframe(df.head(10))

    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Informa√ß√µes Gerais (Estrutura)")
        
        # Criar um DataFrame com as informa√ß√µes de .info()
        info_df = pd.DataFrame({
            "Coluna": df.columns,
            "Valores N√£o Nulos": df.count().values,
            "Tipo de Dado (Dtype)": df.dtypes.values
        })
        
        st.dataframe(info_df, use_container_width=True)

    with col2:
        st.subheader("Estat√≠sticas Descritivas (.describe)")
        st.dataframe(df.describe(), use_container_width=True)

# --- CONTROLE PRINCIPAL ---
if df is not None:
    if page == "Predi√ß√£o em Tempo Real":
        prediction_section()
    elif page == "An√°lise Explorat√≥ria":
        eda_section()
    elif page == "Modelagem & M√©tricas":
        import plotly.graph_objects as go # Importar aqui para evitar carregar em todas as p√°ginas
        modeling_section()
    elif page == "Vis√£o Geral dos Dados":

        data_overview_section()
