# app.py

import streamlit as st
import pandas as pd
import joblib
import os
import kagglehub
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from tensorflow import keras
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.model_selection import train_test_split
import numpy as np

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="An√°lise e Predi√ß√£o de Manuten√ß√£o de Pavimentos",
    page_icon="üõ£Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- FUN√á√ïES DE CACHE E CARREGAMENTO ---
@st.cache_resource
def load_data_and_model():
    """Carrega dados e modelos com cache para melhor performance."""
    try:
        # Cria o diret√≥rio 'models' se n√£o existir
        os.makedirs("models", exist_ok=True)
        
        # Carrega o dataset do Kaggle
        path = kagglehub.dataset_download("gifreysulay/pavement-dataset")
        
        # O dataset vem num arquivo zip, ent√£o precisamos encontrar o CSV dentro dele
        csv_file_path = ""
        for f in os.listdir(path):
            if f.endswith('.csv'):
                csv_file_path = os.path.join(path, f)
                break
        
        if not csv_file_path:
            st.error("Arquivo CSV n√£o encontrado no dataset do Kaggle.")
            return None, None, None, None, None, None

        df_pavement = pd.read_csv(csv_file_path)
        df_pavement = df_pavement.sample(10000, random_state=42)

        # Caminhos dos modelos e do hist√≥rico
        MODEL_PATH = os.path.join("models", "best_pavement_model.keras")
        PIPELINE_PATH = os.path.join("models", "pavement_preprocessor.pkl")
        HISTORY_PATH = os.path.join("models", "training_history.pkl")

        # Carrega o modelo, pipeline e hist√≥rico
        model = keras.models.load_model(MODEL_PATH)
        pipeline = joblib.load(PIPELINE_PATH)
        history = joblib.load(HISTORY_PATH)
        
        st.success("‚úÖ Dados e modelos carregados com sucesso!")
        return df_pavement, model, pipeline, history

    except Exception as e:
        st.error(f"‚ùå Erro ao carregar dados/modelo: {e}")
        st.info("Certifique-se de que os arquivos 'best_pavement_model.keras', 'pavement_preprocessor.pkl', e 'training_history.pkl' est√£o na pasta 'models'.")
        return None, None, None, None

# --- CARREGAMENTO INICIAL ---
df, model, pipeline, history = load_data_and_model()

# --- SIDEBAR DE NAVEGA√á√ÉO ---
st.sidebar.title("üõ£Ô∏è An√°lise e Predi√ß√£o de Manuten√ß√£o de Pavimentos")
st.sidebar.markdown("---")
page = st.sidebar.radio(
    "Navegue pelas se√ß√µes:",
    ["Predi√ß√£o em Tempo Real", "An√°lise Explorat√≥ria", "Modelagem & M√©tricas", "Vis√£o Geral dos Dados"]
)
st.sidebar.markdown("---")
st.sidebar.info(
    """
    **Desenvolvido por:** Wallas Borges Ara√∫jo  
    """
)
# --- SE√á√ÉO DE PREDI√á√ÉO ---
def prediction_section():
    st.header("üîÆ Predi√ß√£o de Necessidade de Manuten√ß√£o")
    st.markdown("Insira os dados do segmento de pavimento para obter uma predi√ß√£o em tempo real.")

    # Formul√°rio para entrada do usu√°rio
    with st.form("prediction_form"):
        col1, col2, col3 = st.columns(3)

        with col1:
            pci = st.slider("√çndice de Condi√ß√£o do Pavimento (PCI)", 0.0, 100.0, 50.0, 0.1)
            rutting = st.slider("Afundamento (Rutting em mm)", 8.0, 23.0, 15.0, 0.1)
            road_type = st.selectbox("Tipo de Via (Road Type)", options=df['Road Type'].unique(), index=0)

        with col2:
            aadt = st.number_input("Tr√°fego M√©dio Di√°rio Anual (AADT)", min_value=0, max_value=200000, value=10000)
            iri = st.slider("√çndice de Irregularidade Internacional (IRI)", 0.0, 2.0, 0.8, 0.01)
            asphalt_type = st.selectbox("Tipo de Asfalto (Asphalt Type)", options=df['Asphalt Type'].unique(), index=0)

        with col3:
            last_maintenance = st.number_input("Ano da √öltima Manuten√ß√£o", min_value=1950, max_value=2025, value=2018)
            avg_rainfall = st.slider("Precipita√ß√£o M√©dia Anual (mm)", 10.0, 120.0, 65.0, 0.1)
        
        submit_button = st.form_submit_button("Executar Predi√ß√£o")

    if submit_button:
        # Criar DataFrame com os dados de entrada
        input_data = pd.DataFrame({
            'PCI': [pci],
            'Road Type': [road_type],
            'AADT': [aadt],
            'Asphalt Type': [asphalt_type],
            'Last Maintenance': [last_maintenance],
            'Average Rainfall': [avg_rainfall],
            'Rutting': [rutting],
            'IRI': [iri]
        })

        st.markdown("---")
        st.subheader("Dados Inseridos pelo Usu√°rio:")
        st.dataframe(input_data)

        # Pr√©-processar os dados e fazer a predi√ß√£o original
        processed_data = pipeline.transform(input_data)
        prediction_proba = model.predict(processed_data)[0][0]
        prediction = 1 if prediction_proba > 0.5 else 0

        # Exibir o resultado
        st.subheader("Resultado da Predi√ß√£o:")
        if prediction == 1:
            st.error(f"üö® **Precisa de Manuten√ß√£o** (Probabilidade: {prediction_proba:.2%})")
        else:
            st.success(f"‚úÖ **N√£o Precisa de Manuten√ß√£o** (Probabilidade de precisar: {prediction_proba:.2%})")

        st.progress(float(prediction_proba))
        st.markdown("---")

        # --- AN√ÅLISE T√âCNICA DE SENSIBILIDADE COM GR√ÅFICO ---
        with st.expander("üî¨ Clique para ver a An√°lise Detalhada"):
            st.subheader("An√°lise de Contribui√ß√£o dos Atributos")
            st.markdown("""
            O gr√°fico interativo abaixo mostra o impacto de cada atributo na predi√ß√£o. Simulamos o "pior cen√°rio" para cada vari√°vel e medimos o quanto a probabilidade de manuten√ß√£o **aumentaria**. 
            
            **Passe o mouse sobre as barras para ver os detalhes.**
            """)

            feature_impacts = {}
            # Definimos os piores cen√°rios para cada atributo
            worst_scenarios = {
                'PCI': df['PCI'].min(),
                'Rutting': df['Rutting'].max(),
                'IRI': df['IRI'].max(),
                'Last Maintenance': df['Last Maintenance'].min(),
                'AADT': df['AADT'].max(),
                'Average Rainfall': df['Average Rainfall'].max()
            }

            for feature, worst_value in worst_scenarios.items():
                temp_data = input_data.copy()
                temp_data[feature] = worst_value
                temp_processed = pipeline.transform(temp_data)
                new_proba = model.predict(temp_processed)[0][0]
                impact = new_proba - prediction_proba
                # Garantimos que o impacto n√£o seja negativo (s√≥ nos interessa o aumento do risco)
                feature_impacts[feature] = max(0, impact)

            # Ordena os atributos pelo maior impacto e cria um DataFrame
            sorted_impacts = sorted(feature_impacts.items(), key=lambda item: item[1], reverse=False) # Invertido para plotagem correta
            impact_df = pd.DataFrame(sorted_impacts, columns=['Atributo', 'Impacto na Probabilidade'])

            # Cria o gr√°fico de barras interativo com Plotly
            fig = px.bar(
                impact_df,
                x='Impacto na Probabilidade',
                y='Atributo',
                orientation='h',
                title='Sensibilidade da Predi√ß√£o a Piores Cen√°rios',
                text='Impacto na Probabilidade'
            )
            
            # Melhora a formata√ß√£o do gr√°fico
            fig.update_traces(
                texttemplate='%{text:.2%}', 
                textposition='outside',
                marker_color='#EF553B' # Cor vermelha para indicar risco
            )
            fig.update_layout(
                yaxis_title="Atributo",
                xaxis_title="Aumento na Probabilidade de Manuten√ß√£o",
                xaxis_tickformat='.0%',
                uniformtext_minsize=8, 
                uniformtext_mode='hide'
            )
            
            st.plotly_chart(fig, use_container_width=True)

            st.subheader("An√°lise dos Fatores Chave")
            st.markdown("""
            Com base no comportamento geral do modelo, observe os seguintes fatores de risco:

            * **Fatores que AUMENTAM a necessidade de manuten√ß√£o:**
                * üìâ **PCI baixo:** Valores abaixo de 60-70 s√£o um forte indicativo.
                * üìà **Rutting (Afundamento) alto:** Geralmente acima de 15-18mm.
                * üìà **IRI (Irregularidade) alto:** Valores se aproximando de 1.5 ou mais.
                * üóìÔ∏è **√öltima Manuten√ß√£o distante:** Anos muito antigos aumentam significativamente o risco.

            * **Fatores que DIMINUEM a necessidade de manuten√ß√£o:**
                * üìà **PCI alto:** Pavimentos com PCI acima de 85 raramente necessitam de interven√ß√£o imediata.
                * üìâ **Rutting e IRI baixos:** Indicam uma superf√≠cie de boa qualidade.
                * üÜï **Manuten√ß√£o Recente:** Interven√ß√µes nos √∫ltimos anos reduzem drasticamente a necessidade de uma nova.
            """)

# --- SE√á√ÉO DE AN√ÅLISE EXPLORAT√ìRIA (EDA) ---
# --- SE√á√ÉO DE AN√ÅLISE EXPLORAT√ìRIA (EDA) AMPLIADA ---
def eda_section():
    st.header("üìä An√°lise Explorat√≥ria dos Dados (EDA)")
    st.markdown("Visualiza√ß√µes interativas para entender a distribui√ß√£o e correla√ß√£o dos dados.")
    
    # Filtros na sidebar
    st.sidebar.subheader("üéõÔ∏è Filtros de Dados")
    
    # Filtro por Tipo de Rodovia
    road_types = st.sidebar.multiselect(
        "Tipo de Rodovia:",
        options=df['Road Type'].unique(),
        default=df['Road Type'].unique()
    )
    
    # Filtro por PCI
    pci_range = st.sidebar.slider(
        "Faixa de PCI:",
        min_value=float(df['PCI'].min()),
        max_value=float(df['PCI'].max()),
        value=(float(df['PCI'].min()), float(df['PCI'].max()))
    )
    
    # Filtro por necessidade de manuten√ß√£o
    maintenance_filter = st.sidebar.selectbox(
        "Necessidade de Manuten√ß√£o:",
        options=['Todos', 'Sim', 'N√£o']
    )
    
    # Aplicar filtros
    filtered_df = df[
        (df['Road Type'].isin(road_types)) &
        (df['PCI'] >= pci_range[0]) &
        (df['PCI'] <= pci_range[1])
    ]
    
    if maintenance_filter != 'Todos':
        filter_value = 1 if maintenance_filter == 'Sim' else 0
        filtered_df = filtered_df[filtered_df['Needs Maintenance'] == filter_value]
    
    # M√©tricas principais
    st.subheader("üìä M√©tricas Principais")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        total_samples = len(filtered_df)
        st.metric("Amostras Filtradas", total_samples)
    
    with col2:
        maintenance_rate = filtered_df['Needs Maintenance'].mean() * 100
        st.metric("Taxa de Manuten√ß√£o", f"{maintenance_rate:.1f}%")
    
    with col3:
        avg_pci = filtered_df['PCI'].mean()
        st.metric("PCI M√©dio", f"{avg_pci:.1f}")
    
    with col4:
        high_risk = len(filtered_df[filtered_df['PCI'] < 40])
        st.metric("Pavimentos Cr√≠ticos", high_risk)
    
    # Abas para diferentes visualiza√ß√µes
    tab1, tab2, tab3, tab4 = st.tabs(["üìà Distribui√ß√µes", "üîç Correla√ß√µes", "üìã Dados Detalhados", "üéØ Insights"])
    
    with tab1:
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribui√ß√£o da classe alvo
            fig = px.pie(
                filtered_df, 
                names='Needs Maintenance',
                title='Distribui√ß√£o de Necessidade de Manuten√ß√£o',
                color='Needs Maintenance',
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Distribui√ß√£o do PCI por tipo de manuten√ß√£o
            fig = px.histogram(
                filtered_df, 
                x='PCI',
                color='Needs Maintenance',
                nbins=20,
                title='Distribui√ß√£o do PCI por Status de Manuten√ß√£o',
                barmode='overlay'
            )
            st.plotly_chart(fig, use_container_width=True)

            st.markdown("---")
        # Distribui√ß√£o das vari√°veis num√©ricas (vers√£o original)
        st.subheader("Distribui√ß√£o das Vari√°veis Num√©ricas")
        numeric_features = ['PCI', 'IRI', 'Rutting', 'AADT', 'Last Maintenance', 'Average Rainfall']
        feature_to_plot = st.selectbox("Selecione uma vari√°vel para visualizar a distribui√ß√£o:", numeric_features, key="distrib_original")
        fig = px.histogram(df, x=feature_to_plot, color='Needs Maintenance', marginal="box", 
                        title=f'Distribui√ß√£o de {feature_to_plot} por Classe de Manuten√ß√£o',
                        )
        st.plotly_chart(fig, use_container_width=True)
        
        st.markdown("""
        - **PCI (√çndice de Condi√ß√£o do Pavimento):** Valores mais baixos est√£o fortemente associados √† necessidade de manuten√ß√£o.
        - **Rutting (Afundamento):** Valores mais altos indicam maior probabilidade de manuten√ß√£o.
        - A an√°lise das outras vari√°veis tamb√©m mostra separa√ß√µes claras entre as classes, indicando seu poder preditivo.
        """)
        
        with col2:
            # Distribui√ß√£o por Tipo de Rodovia
            road_maintenance = filtered_df.groupby(['Road Type', 'Needs Maintenance']).size().reset_index(name='Count')
            fig = px.bar(
                road_maintenance,
                x='Road Type',
                y='Count',
                color='Needs Maintenance',
                barmode='group',
                title='Necessidade de Manuten√ß√£o por Tipo de Rodovia',
                color_discrete_map={0: 'green', 1: 'red'}
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # Box plot do PCI por Tipo de Rodovia
            fig = px.box(
                filtered_df,
                x='Road Type',
                y='PCI',
                color='Needs Maintenance',
                title='PCI por Tipo de Rodovia e Status de Manuten√ß√£o'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with tab2:
        # Matriz de correla√ß√£o
        st.subheader("üîó Matriz de Correla√ß√£o")
        numeric_cols = filtered_df.select_dtypes(include=[np.number]).columns
        corr_matrix = filtered_df[numeric_cols].corr()
        
        fig = px.imshow(
            corr_matrix,
            text_auto=True,
            aspect="auto",
            title="Matriz de Correla√ß√£o entre Vari√°veis Num√©ricas",
            color_continuous_scale='RdBu_r'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Scatter plot interativo
        st.subheader("üìä An√°lise de Relacionamento")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            x_axis = st.selectbox("Eixo X:", numeric_cols, index=0)
        with col2:
            y_axis = st.selectbox("Eixo Y:", numeric_cols, index=1)
        with col3:
            color_by = st.selectbox("Colorir por:", ['Needs Maintenance', 'Road Type', 'Asphalt Type'])
        
        fig = px.scatter(
            filtered_df,
            x=x_axis,
            y=y_axis,
            color=color_by,
            hover_data=filtered_df.columns.tolist(),
            title=f"Rela√ß√£o entre {y_axis} e {x_axis}",
            size_max=10
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with tab3:
        # Dataframe interativo
        st.subheader("üìã Dados Filtrados")
        
        # Op√ß√µes de visualiza√ß√£o
        view_option = st.radio(
            "Tipo de Visualiza√ß√£o:",
            ["Primeiras 100 linhas", "Amostra aleat√≥ria", "Dados agregados", "Estat√≠sticas descritivas"]
        )
        
        if view_option == "Primeiras 100 linhas":
            st.dataframe(filtered_df.head(100), use_container_width=True, height=400)
        elif view_option == "Amostra aleat√≥ria":
            sample_size = st.slider("Tamanho da amostra:", 10, 200, 50)
            st.dataframe(filtered_df.sample(sample_size), use_container_width=True, height=400)
        elif view_option == "Dados agregados":
            group_by = st.selectbox("Agrupar por:", ['Road Type', 'Asphalt Type', 'Needs Maintenance'])
            aggregated = filtered_df.groupby(group_by).agg({
                'PCI': ['mean', 'min', 'max', 'std'],
                'AADT': 'mean',
                'Last Maintenance': 'mean',
                'Needs Maintenance': ['mean', 'sum']
            }).round(2)
            st.dataframe(aggregated, use_container_width=True)
        else:
            st.dataframe(filtered_df.describe(), use_container_width=True)
        
        # Bot√£o para download
        csv = filtered_df.to_csv(index=False)
        st.download_button(
            label="üì• Download dos dados filtrados (CSV)",
            data=csv,
            file_name="dados_pavimentos_filtrados.csv",
            mime="text/csv"
        )
    
    with tab4:
        st.subheader("üéØ Insights Autom√°ticos")
        
        # An√°lises autom√°ticas
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**üìà Estat√≠sticas de Manuten√ß√£o:**")
            
            # An√°lise por Tipo de Rodovia
            maintenance_by_road = filtered_df.groupby('Road Type')['Needs Maintenance'].agg(['mean', 'count']).round(3)
            maintenance_by_road['mean'] = maintenance_by_road['mean'] * 100
            
            for road_type, row in maintenance_by_road.iterrows():
                status = "üî¥" if row['mean'] > 30 else "üü°" if row['mean'] > 15 else "üü¢"
                st.write(f"{status} **{road_type}**: {row['mean']:.1f}% ({int(row['count'])} amostras)")
            
            st.write("**üìä Distribui√ß√£o de PCI:**")
            pci_stats = filtered_df['PCI'].describe()
            st.write(f"- M√©dia: {pci_stats['mean']:.1f}")
            st.write(f"- Mediana: {pci_stats['50%']:.1f}")
            st.write(f"- M√≠nimo: {pci_stats['min']:.1f}")
            st.write(f"- M√°ximo: {pci_stats['max']:.1f}")
        
        with col2:
            st.write("**üîç Alertas e Recomenda√ß√µes:**")
            
            # Alertas baseados nos dados
            critical_pci = len(filtered_df[filtered_df['PCI'] < 40])
            if critical_pci > 0:
                st.error(f"üö® **{critical_pci} pavimentos em condi√ß√£o cr√≠tica** (PCI < 40)")
            
            high_maintenance = filtered_df['Needs Maintenance'].mean()
            if high_maintenance > 0.3:
                st.warning(f"‚ö†Ô∏è **Alta taxa de manuten√ß√£o**: {high_maintenance:.1%}")
            elif high_maintenance < 0.1:
                st.success(f"‚úÖ **Baixa taxa de manuten√ß√£o**: {high_maintenance:.1%}")
            
            # Correla√ß√£o mais forte com necessidade de manuten√ß√£o
            if 'Needs Maintenance' in numeric_cols:
                correlations = filtered_df[numeric_cols].corr()['Needs Maintenance'].abs().sort_values(ascending=False)
                if len(correlations) > 1:
                    strongest_corr = correlations.index[1]
                    corr_value = correlations.iloc[1]
                    st.info(f"üí° **Maior correla√ß√£o com manuten√ß√£o**: {strongest_corr} ({corr_value:.3f})")

 


# --- SE√á√ÉO DE MODELAGEM E M√âTRICAS ---
def modeling_section():
    st.header("‚öôÔ∏è Modelagem e M√©tricas de Avalia√ß√£o")
    st.markdown("Avalia√ß√£o da performance do modelo de Redes Neurais.")

    # Preparar dados para reavalia√ß√£o
    X = df.drop(['Needs Maintenance', 'Segment ID'], axis=1)
    y = df['Needs Maintenance']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    X_test_processed = pipeline.transform(X_test)
    y_pred_proba = model.predict(X_test_processed)
    y_pred = (y_pred_proba > 0.5).astype(int)

    st.subheader("Curvas de Treinamento")
    fig, ax = plt.subplots(1, 2, figsize=(14, 5))
    # Curva de Acur√°cia
    ax[0].plot(history['accuracy'], label='Acur√°cia de Treino')
    ax[0].plot(history['val_accuracy'], label='Acur√°cia de Valida√ß√£o')
    ax[0].set_title('Acur√°cia por √âpoca')
    ax[0].set_xlabel('√âpoca')
    ax[0].set_ylabel('Acur√°cia')
    ax[0].legend()
    # Curva de Perda
    ax[1].plot(history['loss'], label='Perda de Treino')
    ax[1].plot(history['val_loss'], label='Perda de Valida√ß√£o')
    ax[1].set_title('Perda por √âpoca')
    ax[1].set_xlabel('√âpoca')
    ax[1].set_ylabel('Perda')
    ax[1].legend()
    st.pyplot(fig)

    st.subheader("M√©tricas de Classifica√ß√£o")
    report = classification_report(y_test, y_pred, output_dict=True)
    st.dataframe(pd.DataFrame(report).transpose())

    st.subheader("M√©tricas Principais")
    acc = report['accuracy']
    recall = report['1']['recall']
    f1 = report['1']['f1-score']
    
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    roc_auc = auc(fpr, tpr)

    m1, m2, m3, m4 = st.columns(4)
    m1.metric("Acur√°cia", f"{acc:.2%}")
    m2.metric("Recall (Classe 1)", f"{recall:.2%}")
    m3.metric("F1-Score (Classe 1)", f"{f1:.2%}")
    m4.metric("ROC AUC", f"{roc_auc:.3f}")
    
    st.markdown("---")
    
    col3, col4 = st.columns(2)
    with col3:
        st.subheader("Matriz de Confus√£o")
        cm = confusion_matrix(y_test, y_pred)
        fig_cm = px.imshow(cm, text_auto=True, aspect="auto",
                           labels=dict(x="Predito", y="Verdadeiro"),
                           x=['N√£o Precisa', 'Precisa'],
                           y=['N√£o Precisa', 'Precisa'],
                           color_continuous_scale='Greens')
        st.plotly_chart(fig_cm, use_container_width=True)

    with col4:
        st.subheader("Curva ROC")
        fig_roc = go.Figure()
        fig_roc.add_shape(type='line', line=dict(dash='dash'),x0=0, x1=1, y0=0, y1=1)
        fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, name=f'AUC={roc_auc:.3f}', mode='lines'))
        fig_roc.update_layout(
                              xaxis_title='Taxa de Falsos Positivos',
                              yaxis_title='Taxa de Verdadeiros Positivos',
                              yaxis=dict(scaleanchor="x", scaleratio=1),
                              xaxis=dict(constrain='domain'))
        st.plotly_chart(fig_roc, use_container_width=True)

# --- SE√á√ÉO DE VIS√ÉO GERAL DOS DADOS ---
def data_overview_section():
    st.header("üìÑ Vis√£o Geral do Dataset")
    st.markdown("Uma amostra dos dados utilizados para treinar o modelo.")
    
    st.subheader("Amostra do DataFrame")
    st.dataframe(df.head(10))

    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Informa√ß√µes Gerais (Estrutura)")
        
        # Criar um DataFrame com as informa√ß√µes de .info()
        info_df = pd.DataFrame({
            "Coluna": df.columns,
            "Valores N√£o Nulos": df.count().values,
            "Tipo de Dado (Dtype)": df.dtypes.values
        })
        
        st.dataframe(info_df, use_container_width=True)

    with col2:
        st.subheader("Estat√≠sticas Descritivas (.describe)")
        st.dataframe(df.describe(), use_container_width=True)

# --- CONTROLE PRINCIPAL ---
if df is not None:
    if page == "Predi√ß√£o em Tempo Real":
        prediction_section()
    elif page == "An√°lise Explorat√≥ria":
        eda_section()  # Agora usa a vers√£o ampliada
    elif page == "Modelagem & M√©tricas":
        import plotly.graph_objects as go
        modeling_section()
    elif page == "Vis√£o Geral dos Dados":
        data_overview_section()
